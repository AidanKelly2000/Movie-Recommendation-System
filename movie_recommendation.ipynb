{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Databricks notebook for the movie recomendation code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_filename = \"dbfs:/mnt/Files/Validated/ratings.csv\"\n",
    "movies_filename = \"dbfs:/mnt/Files/Validated/movies.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%fs\n",
    "ls /mnt/Files/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Little analysis on the movies.csv\n",
    "We will create 2 dataframes for our analysis which will make the visualization with Databricks display function pretty straightforward-\n",
    "1. movies_based_on_time - We will drop the genres here final schema will be (movie_id,name, Year)\n",
    "2. movies_based_on_genres - Final schema would look like (movie_id,name_with_year,one_genre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "\n",
    "#working only on movies.csv right now\n",
    "movies_with_genres_df_schema = StructType(\n",
    "[StructField('ID', IntegerType()),\n",
    "StructField('title', StringType()),\n",
    "StructField('genres',StringType())]\n",
    ")\n",
    "\n",
    "movies_df_schema = StructType(\n",
    "[StructField('ID', IntegerType()),\n",
    "StructField('title', StringType())]\n",
    ") \n",
    "\n",
    "#dropping the genres. Also, we will transform the df to include the Year later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the dataframes\n",
    "movies_df = sqlContext.read.format('com.databricks.spark.csv').options(header=True,\n",
    "inferSchema=False).schema (movies_df_schema).load(movies_filename)\n",
    "\n",
    "movies_with_genres_df = sqlContext.read.format('com.databricks.spark.csv').options(header=True,\n",
    "inferSchema=False).schema(movies_with_genres_df_schema).load(movies_filename)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore the dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df.show(4, truncate=False) # we will also use this for collaborative filtering\n",
    "movies_with_genres_df.show(4, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transforming the Dataframes\n",
    "from pyspark.sql.functions import split, regexp_extract\n",
    "\n",
    "movies_with_year_df = movies_df.select('ID', 'title', regexp_extract('title','\\((\\d+)\\)',1).alias('year'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataframes after transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_with_year_df.show(4, truncate=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we will gain some insights from the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from here we can look at the count and find what year the maximum number of movies were produced (it was in 2009)\n",
    "display(movies_with_year_df.groupBy ( 'year').count().orderBy('count', ascending = False))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's create the ratings dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#again for avoiding the action we are explicitly defining the schema, this ratings df contains over 20 million ratings\n",
    "ratings_df_schema = StructType(\n",
    "[StructField('userId', Integer Type()), \n",
    " StructField('movieId', IntegerType()), \n",
    " StructField('rating', DoubleType())])\n",
    "#we are dropping the Time Stamp column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the ratings df\n",
    "ratings_df = sqlContext.read.format('com.databricks.spark.csv').options(header=True,\n",
    "            inferSchema=False).schema(ratings_df_schema).load(ratings_filename)\n",
    "ratings_df.show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cache the dataframes for quick access\n",
    "\n",
    "ratings_df.cache()\n",
    "movies_df.cache()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global Popularity\n",
    "\n",
    "It is good to know the most popular movies, movies with the highest average ratings will be constrained on the number of reviews given. Similarly we will discard movies where number of reviews is less than 500."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "# From ratingsDF, create a movie_ids_with_avg_ratings_df that combines the two Dataframes\n",
    "movie_ids_with_avg_ratings_df = ratings_df.groupBy('movield').agg(F.count(ratings_df.rating).alias(\"count\"),\n",
    "F.avg(ratings_df.rating).alias(\"average\"))\n",
    "\n",
    "print('movie_ids_with_avg_ratings_df:')\n",
    "\n",
    "movie_ids_with_avg_ratings_df.show(4, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this df will have names with movie_id - make it more understandable\n",
    "\n",
    "movie_names_with_avg_ratings_df = movie_ids_with_avg_ratings_df.join(movies_df, F.col('movieID') == F.col('ID')).drop('ID')\n",
    "movie_names_with_avg_ratings_df.show(4, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#looking at global popularity\n",
    "\n",
    "movies_with_500_ratings_or_more = movie_names_with_avg_ratings_df.filter(movie_names_with_avg_ratings_df['count'] >= 500).orderBy('average', ascending=False)\n",
    "movies_with_500_ratings_or_more.show(truncate=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting in Train, Test, Validation Dataset\n",
    "\n",
    "As with all ML Algorithms, in practice we have to tune parameters and then test accuracy. For this we will split the data into 3 parts: Train, Test(Checking the accuracy of the trained model) and Validation(A way to see how we can tune the hyperparameters). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will hold out 60% for training, 20% for validation and 20% for testing\n",
    "\n",
    "seed = 4\n",
    "(split_60_df, split_a_20_df, split_b_20_df) = ratings_df.randomSplit([0.6,0.2,0.2],seed)\n",
    "\n",
    "# Let's cache these datasets for performance\n",
    "training_df = split_60_df.cache()\n",
    "validation_df = split_a_20_df.cache()\n",
    "test_df = split_b_20_df.cache()\n",
    "\n",
    "print('Training: {0}, validation: {1}, test: {2}\\n'.format(\n",
    "training_df.count(), validation_df.count(), test_df.count())\n",
    ")\n",
    "\n",
    "training_df.show(4,truncate = False)\n",
    "\n",
    "validation_df.show(4, truncate =False)\n",
    "\n",
    "test_df.show(4,truncate = False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternating Least Square (ALS)\n",
    "\n",
    "A challenge for collaborative filtering is how to provide ratings to a new user (a user who has not provided any ratings at all). Some recommendation systems choose to provide new users with a set of default ratings (e.g., an average value across all ratings), while others choose to provide no ratings for new users. Spark's ALS algorithm yields a NaN (Not a Number ) value when asked to provide a rating for a new user.\n",
    "Using the ML Pipeline's CrossValidator with ALS is thus problematic, because cross validation involves dividing the training data into a set of folds (e.g., three sets) and then using those folds for testing and evaluating the parameters during the parameter grid search process. It is likely that some of the folds will contain users that are not in the other folds, and, as a result, ALS produces NaN values for those new users. When the CrossValidator uses the Evaluator (RMSE) to compute an error metric, the RMSE algorithm will return NaN. This will make all of the parameters in the parameter grid appear to be equally good (or bad). You can read the discussion on Spark JIRA 14489 about this issue. There are proposed workarounds of having ALS provide default values or having RMSE drop NaN values. Both introduce potential issues. We have chosen to have RMSE drop NaN values. While this does not solve the underlying issue of ALS not predicting a value for a new user, it does provide some evaluation value, We manually implement the parameter grid search process using a for loop (below) and remove the NaN values before using RMSE.\n",
    "\n",
    "For a production application, you would want to cosider the tradeoffs in how to handle new users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
